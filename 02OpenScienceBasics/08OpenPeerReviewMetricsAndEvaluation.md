## <img src="/Images/Icons/peer_review.png" width="300" height="300" />

## 8. Revisión por pares abierta, métricas y evaluación 

### ¿En qué consiste?

Ser un investigador implica estar sujeto a una evaluación constante. La academia es una "economía del prestigio", donde el valor académico se basa en  la evaluación que los investigadores y sus colaboradores reciben de sus pares u otro tipo de tomadores de decisiones,  y se basa generalmente en el prestigio de su producción científico-académica  \(Blackmore and Kandiko, 2011\). En esta sección será, por lo tanto, importante distinguir entre la evaluación de los trabajos y la evaluación de los propios investigadores. Tanto los trabajos de  investigación como los investigadores se evalúan principalmente siguiendo dos métodos: la revisión por pares y las métricas, el  primero de tipo cualitativo y el segundo, cuantitativo. 

La revisión por pares se utiliza principalmente para evaluar los trabajos de investigación. Es el mecanismo formal utilizado para valorar la calidad de los manuscritos académicos \(ej. artículos de revistas, libros, postulaciones a fondos de financiamiento y comunicaciones a  congresos \) llevado a cabo por pares, cuya retroalimentación y juicio se emplean para la mejora de los trabajos y la toma de decisiones con respecto a su aceptación \(de publicación, de adjudicación de fondos de financiamiento o de su presentación\).  La revisión por pares abierta tiene significados distintos para distintas personas y comunidades, se ha sido definido como "un término que engloba (umbrella term) diversas formas a las que los  modelos de  evaluacion por pares pueden adaptarse para estar en consonancia con  los objetivos de la Ciencia Abierta" \(Ross-Hellauer, 2017\). Su principal característica es que tanto autores como recensores conocen sus identidades recíprocamente ("identidades abiertas") \(es decir, evaluación por el sistema no ciego\), e "informes abiertos", donde los informes de revisión se publican junto con el artículo correspondiente. Estos dos elementos pueden combianrse, aunque no es del todo necesario, y pueden complementarse con otras innovaciones, como "participación abierta", donde los miembros de una comunidad ampliada son capaces de contribuir al proceso de revisión, o "interacción abierta", donde la discusión recíproca entre autor(es) y revisor(es) es fomentada, y "manuscritos de revisión por pares abierta", donde los manuscritos son puestos a disposición de manera inmediata antes de cualquier procedimiento formal de revisión por pares \(ya sea internamente como parte de los flujos de trabajo de una revista o externamente a través de un servidor de preprints\). 

Una vez que han pasado la revisión por pares, las publicaciones se convierten en la principal medida del trabajo de un investigador (de ahí la frase "publicar o perecer"). Sin embargo, evaluar la calidad de las publicaciones es difícil y subjetivo. Aunque algunas iniciativas de evaluación utilizan revisión por pares,  como el Marco de Excelencia de la Investigación del Reino Unido (Research Excellence Framework), las evaluaciones generalmente suelen estar basadas en __métricas__ como el número de citaciones generadas por publicación (índice h), o a través del nivel de prestigio percibido de una revista académica donde un artículo fue publicado (cuantificado a través del Factor de Impacto de Revistas). La predominancia de dichas métricas y la forma en que pueden distorsionar incentivos ha sido enfatizada en años recientes a través de declaraciones como el Manifiesto de Leiden y la Declaración de San Francisco sobre Evaluación de la Investigación (DORA). 

En años reciente, las "Métricas Alternativas" o  [altmétricas](https://www.altmetric.com) se han vuelto un tema de debate en relación a los esfuerzos por realizar evaluaciones balanceadas de la investigación que complementen el número de citaciones, recopilando otras métricas de impacto de la investigación generadas en línea, incluyendo bookmarks, enlaces web, posteos de blogs, tweets, likes, shares, aparición en prensa y otros similares. Subyacente a todos estos temas asociados a métricas está el hecho de que son producidos por entidades con fines comerciales (ej., Clarivite Analytics y Elsevier), basados en sistemas privados, que puede generar problemas en relación a su transparencia. 

## <img src="/Images/Icons/umbrella.png" width="150" height="150" />
### Justificación

#### Revisión por pares abierta 
Comenzando en el siglo XVII en la Real Sociedad de Londres (Royal Society of London) (1662) y en la Academia Real de Ciencias de París (Académie Royale des Sciences de Paris ) (1699), y dado el privilegio de la ciencia de censurarse a sí misma en vez de a través de la iglesia, tomó muchos años para que la revisión por pares fuera establecida formalmente en el quehacer científico. La revisión por pares, como mecanismo formalizado, es mucho más joven de lo que muchos asumen. Por ejemplo, la revista Nature sólo la introdujo en el año 1967. Aunque algunas encuestas muestran que los investigadores valoran la revisión por pares, también piensan que podría ser mejorado. Muchas veces hay quejas de que las revisiones toman much tiempo, de que son inconsistentes y que muchas veces fallan en detectar errores, y que el anonimato sirve de escudo para sesgos. La revisión por pares abierta (Open peer review \(OPR\)) por tanto, busca promover mayor transparencia y participación en los procesos de revisión por pares, formales e informales. Ser un revisor es una oportunidad para los investigadores de involucrarse con investigación novedosa, crear redes académicas y experticia, y refinar su propia escritura. Es un elemento crucial del control de calidad del trabajo académico. Sin embargo, en general, los investigadores normalmente no reciben una capacitación formal sobre cómo realizar revisiones por pares. Incluso si los investigadores mismos se sienten confiados con la revisión por pares tradicional, las nuevas formas de revisión por pares abierta presentan nuevos desafíos y oportunidades. Como la OPR cubre un grupo de prácticas tan diverso, hay muchas consideraciones que tanto revisores como autores deben tomar en cuenta. 

## <img src="/Images/02 Open Science Basics/02_open_peer_review.png" />

Con respecto a la evaluación, los sistemas de recompensa y métricas en la ciencia y la academia no están \(aun\) en línea con la Ciencia Abierta. Las métricas utilizadas para evaluar la investigación \(ej. Factor de Impacto, índice-h\) no miden -  y por tanto, no premian - las prácticas de ciencia abierta. La revisión por pares abierta no es necesariamente reconocida como un "objeto académico" en escenarios de avance de la carrera profesional (ej. en muchos casos, los revisores de concursos académicos no consideran como objetos académicos ni las revisiones por pares abiertas más brillantes\). Es más, muchas métricas de evaluación - especialmente cierto tipo de bibliometrías - no son tan abiertas y transparentes como la comunidad quisiera. 

Bajo estas circunstancias, en el mejor de los casos las prácticas de Ciencia Abierta son vistas como una carga adicional que no tiene reconocimiento. En el peor, son vistas como actividades que perjudican las posibilidades futuras de financiamiento y promisión, así como de titularidad. Un [reporte reciente de la Comisión Europea (2017)](https://doi.org/10.2777/75255) reconoce que hay básicamente dos aproximaciones para la implementación de la Ciencia Abierta, y las formas en que reconocimientos y evaluaciones pueden apoyarla: 

1. Simplemente apoyar el status quo promoviendo mayor apertura, construyendo métricas relacionadas y cuantificando productos; 

2. Experimentar prácticas y evaluaciones alternativas de investigación, datos abiertos, ciencia ciudadana y educación abierta. 

Cada vez más agencias de financiamiento e instituciones están dando algunos pasos en estas direcciones, por ejemplo, alejándose de evaluaciones simplemente numéricas, e incluyendo narrativas e indicadores de impacto social en sus ejercicios de evaluación. Otros pasos que estos financistas están tomando son el permitir más tipos de productos de investigación \(como preprints\) en postulaciones y el financiamiento de distintos tipos de investigación \(como estudios de repetibilidad\).

## <img src="/Images/Icons/finish.png" width="150" height="150" />
### Objetivos de aprendizaje

1. Reconocer los principales elementos de la revisión por pares abierta y sus potenciales ventajas y desventajas.
2. Entender las diferencias entre tipos de métricas utilizadas para evaluar la investigación y a los investigadores.
3. Involucrarse en el debate sobre la forma en que los esquemas de evaluación afectan las maneras de funcionamiento de la academia. 

### Componentes principales
## <img src="/Images/Icons/brain.png" width="150" height="150" />
### Conocimiento
#### Revisión por pares abierta 

Sitios populares para la OPR son editoriales de revistas científicas como Copernicus, Frontiers, BioMed Central, eLife y F1000research.

La revisión por pares abierta, en sus distintas formas, tiene potenciales ventajas para los revisores y autores:

* La revisión con identidades abiertas \(no-ciegas\) promueve mayor transparencia y accountability entre revisores y reduce las oportunidades de sesgos o conflictos de interés no explicitados. 

* Los reportes de revisión abierta agregan otra capa de control de calidad, permitiendo a la comunidad ampliada desmenuzar las revisiones y examinar los procesos de toma de decisiones.

* Identidades abiertas y reportes abiertos, en combinación, se piensa que llevarán a mejores revisiones, dado que la idea de tener su nombre públicamente conectado a un trabajo o ver su revisión publicada, incentiva que los investigadores sean más rigurosos.

* Identidades abiertas y reportes abiertos le permiten a los revisores ganar crédito público por su trabajo de revisión, por tanto incentivando esta vital actividad y permitiendo que el trabajo de revisión sea citado en otras publicaciones y en actividades de desarrollo de carrera asociadas a promoción y titularidad. 

* La participación abierta podría superar los problemas asociados con la selección editorial de revisores \(ej. sesgos, redes cerradas, elitismo\). Especialmente para investigadores jóvenes que no han recibido invitaciones par ser revisores, estos procesos abiertos pueden representar una oportunidad para construir su reputación académica y practicar sus competencias de revisión. 

Existen algunos inconvenientes a los que se debe poner atención, incluyendo:

* Las identidades abiertas remueven las condiciones de anonimidad de los revisores \(a ciegas)\ o los autores y revisores \(doble ciego\) que tradicionalmente han sido implementados para contrarrestar sesgos sociales \(aunque no existe evidencia fuerte que este anonimato haya tenido el efecto deseado\). Es por tanto importante para los revisores cuestionar constantemente sus supuestos para asegurar que sus juicios reflejen sólo la calidad del manuscrito, y no el estatus, historia, o afiliación de el/los autor(es)\). Los autores deben hacer lo mismo al recibir comentarios de la revisión por pares.

* Dar y recibir criticismos es muchas veces un proceso que conlleva inevitablemente reacciones emocionales - los autores y los revisores pueden subjetivamente acordar o no cómo presentar los resultados y/o que es lo que necesita mejora, enmienda o corrección. En el caso de identidades abiertas y/o reportes abiertos, la transparencia podría exacerbar dichas dificultades. Es entonces esencial que los revisores aseguren comunicar los puntos de una manera clara y civilizada, de manera de maximizar las oportunidades de que sea recibido como retroalimentación valiosa por el autor\(es\).

* La falta de anonimidad de los revisores en el caso de identidades abiertas puede subvertir el proceso al desincentivar que los revisores hagan críticas fuertes, especialmente en contra de colegas de estatus superior. 

* Finalmente, debido a estos temas, los revisores potenciales podrían ser más propensos a declinar la solicitud de revisión. 

#### Métricas abiertas

La [Declaración de San Francisco sobre Evaluación de la Investigación \(DORA\)](https://sfdora.org/) recomienda distanciarse de las evaluaciones basadas en revistas científicas, considerando todos los tipos de productos y utilizar varias formas de métricas y evaluaciones narrativas en paralelo. DORA ha sido firmada por miles de investigadores, instituciones, editoriales y agencias de financiamiento, quienes hoy se han comprometido a poner esto en práctica. El [Manifiesto de Leiden](http://www.leidenmanifesto.org/) provee guías sobre cómo utilizar las métricas de manera responsable.

Con respecto a Altmétricas, Priem et al. (2010) aconsejan que las altmétricas tienen los siguientes beneficios: se acumulan de manera más rápida que las citaciones; pueden medir el impacto de los resultados de la investigación distintos de publicaciones científicas (ej. sets de datos, código, protocolos, posteos de blog, tweets, etc.); y pueden proveer distintas medidas de impacto para proyectos individuales. La temporalidad de las almétricas se presenta como una ventaja para investigadores jóvenes, cuyo impacto de investigación puede no estar aún reflejado en un número significativo de citaciones, aún cuando su progresión en la carrera académica dependa de evaluaciones positivas. En adición, las altmétricas pueden ayudar con la identificación temprana de investigación influyente y conexiones potenciales entre investigadores. Un reporte reciente del grupo experto en Altmétricas de la Comisión Europea (Directiva General para Investigación e Innovación, Comisión Europa, 2017) ha identificado desafíos de altmétricas, incluyendo la falta de robustez y su susceptibilidad a ser trucado; que cualquier medida cesa de ser una buena medida una vez que se convierte en un objetivo (‘Ley de Goodhart’); la relativa falta de adopción de redes sociales en algunas disciplinas y regiones geográficas; y la dependencia de entidades comerciales sobre los datos en que se basan estas métricas. 

## <img src="/Images/Icons/gears.png" width="150" height="150" />
### Competencias

Ejercicios de ejemplo

* Los estudiantes trabajan en grupos de tres. Cada individuo escribe una revisión de un texto académico corto.

* Revisar una publicación de un servidor de pre-print. 

* Uso de servicios bibliométricos o de almétricas libres  \(ej. Impactstory, Paperbuzz, Altmetric bookmarklet, Dimensions.ai\) para buscar las métricas de un paper, y luego escribir una breve explicación de cómo exactamente distintas métricas reportadas por cada servicio son calculadas \(es más difícil se lo que piensas; incluye el desafío de encontrar la documentación apropiada de las métricas para incluso aquellos servicios que parecen ser los más transparentes\)

## <img src="/Images/Icons/questions.png" width="150" height="150" />
### Preguntas, obstáculos e ideas equivocadas comunes 
Q: ¿Es justa la evaluación de la investigación?

A: La evaluación de la investigación es justa así como sus métodos y técnicas de evaluación. Las métricas y almétricas tratan de medir la calidad de la investigación a través de la cantidad de productos, lo que puede ser acertado, pero no necesariamente. 


## <img src="/Images/Icons/output.png" width="150" height="150" />
### Resultados de aprendizaje

1. Los estudiantes serán capaces de identificar las revistas de revisión de pares abierta.
2. Los estudiantes estarán al tanto de un rango de métricas, sus ventajas y desventajas. 

## <img src="/Images/Icons/magnifying_glass.png" width="150" height="150" />
### Bibliografía sugerida

* Peer Review the Nuts and Bolts. [A Guide for Early Career Researchers.](http://senseaboutscience.org/wp-content/uploads/2016/09/peer-review-the-nuts-and-bolts.pdf)

* [Peer Reviewers’ Openness Initiative](https://opennessinitiative.org/)

* [Open Rev. ](https://www.openrev.org/)

* [Peerage of Science](https://www.peerageofscience.org/)

* [Make Data Count](https://makedatacount.org/)

* [OpenUP Hub](https://www.openuphub.eu/review)

* [Leiden Manifesto for Research Metrics](http://www.leidenmanifesto.org/)

* [Responsible Metrics](https://responsiblemetrics.org/)

* [NISO Alternative Assessment Metrics \(Altmetrics\) Initiative](http://www.niso.org/standards-committees/altmetrics)

* [Snowball Metrics](https://www.snowballmetrics.com/)

* Directorate-General for Research and Innovation (European Commission): Evaluation of Research Careers Fully Acknowledging Open Science Practices: Rewards, Incentives and/or Recognition for Researchers Practicing Open Science. Report, 14 November 2017: [doi.org/10.2777/75255](https://doi.org/10.2777/75255)



