## <img src="/Images/Icons/peer_review.png" width="300" height="300" />

## 8. Revisión por pares abierta, métricas y evaluación 

### ¿En qué consiste?

Ser un investigador implica estar sujeto a una evaluación constante. La academia es una "economía del prestigio", donde el valor académico se basa en  la evaluación que los investigadores y sus colaboradores reciben de sus pares u otro tipo de tomadores de decisiones,  y se basa generalmente en el prestigio de su producción científico-académica  \(Blackmore and Kandiko, 2011\). En esta sección será, por lo tanto, importante distinguir entre la evaluación de los trabajos y la evaluación de los propios investigadores. Tanto los trabajos de  investigación como los investigadores se evalúan principalmente siguiendo dos métodos: la revisión por pares y las métricas, el  primero de tipo cualitativo y el segundo, cuantitativo. 

La revisión por pares se utiliza principalmente para evaluar los trabajos de investigación. Es el mecanismo formal utilizado para valorar la calidad de los manuscritos académicos \(ej. artículos de revistas, libros, postulaciones a fondos de financiamiento y comunicaciones a  congresos \) llevado a cabo por pares, cuya retroalimentación y juicio se emplean para la mejora de los trabajos y la toma de decisiones con respecto a su aceptación \(de publicación, de adjudicación de fondos de financiamiento o de su presentación\).  La revisión por pares abierta tiene significados distintos para distintas personas y comunidades, se ha sido definido como "un término que engloba (umbrella term) diversas formas a las que los  modelos de  evaluación por pares pueden adaptarse para estar en consonancia con  los objetivos de la Ciencia Abierta" \(Ross-Hellauer, 2017\). Sus dos  principales características son  que tanto autores como recensores conocen sus identidades recíprocamente ("identidades abiertas") \(es decir, evaluación por el sistema no ciego\), y que las recensiones son  "informes abiertos", que se publican junto con el artículo correspondiente. Estos dos elementos pueden combinarse, aunque no es del todo necesario, y pueden complementarse con otro tipo de innovación, como la "participación abierta", donde los miembros de una comunidad determinada pueden contribuir también en el proceso de revisión, o "interacción abierta", donde se fomenta la discusión recíproca entre autor(es) y revisor(es), y "los manuscritos sometidos a una pre-evalaución abierta", en este caso se puede acceder a los manuscritos de manera inmediata antes de cualquier procedimiento formal de revisión por pares \(ya sea internamente como parte de los flujos de trabajo de una revista o externamente a través de un servidor de preprints\). 

Una vez que han pasado la revisión por pares, las publicaciones se convierten en la principal medida del trabajo de un investigador (de ahí la frase "publish or perish"). Sin embargo, evaluar la calidad de las publicaciones es difícil y subjetivo. Aunque algunas iniciativas de evaluación utilizan revisión por pares,  como el Research Excellence Framework del Reino Unido, las evaluaciones generalmente suelen estar basadas en __métricas__ tales como el número de citas generadas por las publicaciones (índice h), o por el  prestigio de la revista académica donde se publicó el artículo (cuantificado a través del Factor de Impacto de la  revista). El predominio de este tipo de métricas y la forma en que pueden distorsionar los incentivos se ha denunciado y puesto de  manifiesto en los últimos años a través de declaraciones como el Manifiesto de Leiden y la Declaración de San Francisco sobre la evaluación de la investigación (DORA). 

Las "Métricas Alternativas" o  [altmétricas](https://www.altmetric.com) se han convertido en  un tema relevante en el debate sobre cómo  complementar la medición basada en el número de citas, con otras mediciones del impacto de los trabajos de investigación  obtenidas de la web, que incluyan bookmarks, enlaces web, comentarios en blogs, tweets, likes, shares, aparición en la prensa,  y otros similares. Además de los posibles temas asociados a las métricas,  está el hecho de que los indices de citas los crean entidades con fines comerciales (ej., Clarivate Analytics y Elsevier), basados en sistemas propietarios, lo que puede generar reticencias repecto a su transparencia. 

## <img src="/Images/Icons/umbrella.png" width="150" height="150" />
### Justificación

#### Revisión por pares abierta 
Desde que en el siglo XVII en la Royal Society of London (1662) y la Académie Royale des Sciences de Paris (1699), asumieron el privilegio de que la ciencia se autocensurase en lugar de hacerlo la iglesia, han apsado muchos años años para que la revisión por pares se estableciera firmemente en el quehacer científico. La revisión por pares, como mecanismo formal, es mucho más joven de lo que muchos piensan. Por ejemplo, la revista Nature la puso en marcha en el año 1967. Aunque algunas encuestas muestran que los investigadores valoran la revisión por pares, también piensan que podría mejorarse. Muchas veces se quejan de que las revisiones toman mucho tiempo, de que son inconsistentes y que muchas veces fallan en la detección de  errores, y que el anonimato puede servir para emitir una opinión sesgada. La revisión por pares abierta (open peer review \(OPR\)) por tanto, busca promover mayor transparencia y participación en los procesos de revisión por pares, formales e informales. Ser un recensor es una oportunidad para los investigadores de involucrarse con una investigación puntera, crear redes académicas y de conocimiento, y mejorar su propia capacidad de comunicación. Es un elemento crucial del control de calidad del trabajo académico. Sin embargo, en general, los investigadores normalmente no reciben una capacitación formal sobre cómo realizar una revisión por pares. A pesar de que los investigadores confían en la evaluación por pares tradicional, las nuevas formas de revisión por pares abierta presentan nuevos desafíos y oportunidades. Como la OPR abarca un grupo de prácticas tan diverso, tanto revisores como autores deben tomar en cuenta las nuevas consideraciones al respecto. 

## <img src="/Images/02 Open Science Basics/02_open_peer_review.png" />

La evaluación por pares, los sistemas de recompensa y las métricas todavía no están en sintonía con la Ciencia Abierta. Las métricas utilizadas para evaluar la investigación \(ej. Factor de Impacto, índice-h\) no miden -  y por tanto, no premian - las prácticas de ciencia abierta. La revisión por pares abierta no está reconocida como una  actividad propiamente  "académica" en escenarios de promoción  profesional (ej. en muchos casos, los tribunales de concursos académicos no consideran como un mérito academico ni las revisiones por pares abiertas más brillantes\). Es más, muchas métricas utilizadas en los concursos de promoción - especialmente cierto tipo de bibliometrías - no son ni tan abiertas ni tan  transparentes como querría la comunidad científica. 

Bajo estas circunstancias, en el mejor de los casos las prácticas de Ciencia Abierta son vistas como una carga adicional que no tiene reconocimiento. En el peor, son vistas como actividades que perjudican las posibilidades  de financiamiento y promoción profesional. Un [informe reciente de la Comisión Europea (2017)](https://doi.org/10.2777/75255) reconoce que existen dos aproximaciones para la implementación de la Ciencia Abierta, y las formas en que el el reconocimiento y la evaluación pueden apoyarla son: 

1. Mantener simplemente el status quo y promover una mayor apertura, mediante nuevas métricas que midan la producción científica 

2. Experimentar con nuevas prácticas  de investigación y alternativas de evaluación, datos abiertos, ciencia ciudadana y de educación abierta. 

Cada vez más, las  agencias de financiamiento y las instituciones académicas están dando algunos pasos en dichas direcciones, por ejemplo, yendo más allá de evaluaciones simplemente numéricas, e incluyendo indicadores de impacto social en sus ejercicios de evaluación. Otras acciones  que las agencias de financiamiento están tomando, son p.e. permitir más tipos de trabajos de investigación \(como preprints\) en postulaciones y el financiamiento de distintos tipos de investigación \(como estudios de repetibilidad\).

## <img src="/Images/Icons/finish.png" width="150" height="150" />
### Objetivos de aprendizaje

1. Reconocer los principales elementos de la revisión por pares abierta y sus potenciales ventajas y desventajas.
2. Entender las diferencias entre tipos de métricas utilizadas para evaluar la investigación y a los investigadores.
3. Involucrarse en el debate sobre la forma en que los esquemas de evaluación afectan las maneras de funcionamiento de la academia. 

### Componentes principales
## <img src="/Images/Icons/brain.png" width="150" height="150" />
### Conocimiento
#### Revisión por pares abierta 

Las editoriales de revistas científicas como Copernicus, Frontiers, BioMed Central, eLife y F1000research, son claro ejemplo del uso de la revisión por pares abierta.

La revisión por pares abierta, en sus distintas formas, tiene potenciales ventajas para los revisores y los autores:

* La revisión con identidades abiertas \(no-enmascaradas\) promueve una mayor transparencia y responsabilidad de los rcensores, y reduce las oportunidades de sesgos o conflictos de interés no explicitados. 

* Los reportes de revisión abierta agregan otra capa de control de calidad, permitiendo a la comunidad ampliada desmenuzar las revisiones y examinar los procesos de toma de decisiones.

* Identidades abiertas y reportes abiertos, en combinación, se piensa que llevarán a mejores revisiones, dado que la idea de tener su nombre públicamente conectado a un trabajo o ver su revisión publicada, incentiva que los investigadores sean más rigurosos.

* Identidades abiertas y reportes abiertos le permiten a los revisores ganar crédito público por su trabajo de revisión, por tanto incentivando esta vital actividad y permitiendo que el trabajo de revisión sea citado en otras publicaciones y en actividades de desarrollo de carrera asociadas a promoción y titularidad. 

* La participación abierta podría superar los problemas asociados con la selección editorial de revisores \(ej. sesgos, redes cerradas, elitismo\). Especialmente para investigadores jóvenes que no han recibido invitaciones par ser revisores, estos procesos abiertos pueden representar una oportunidad para construir su reputación académica y practicar sus competencias de revisión. 

Existen algunos inconvenientes a los que se debe poner atención, incluyendo:

* Las identidades abiertas remueven las condiciones de anonimidad de los revisores \(a ciegas)\ o los autores y revisores \(doble ciego\) que tradicionalmente han sido implementados para contrarrestar sesgos sociales \(aunque no existe evidencia fuerte que este anonimato haya tenido el efecto deseado\). Es por tanto importante para los revisores cuestionar constantemente sus supuestos para asegurar que sus juicios reflejen sólo la calidad del manuscrito, y no el estatus, historia, o afiliación de el/los autor(es)\). Los autores deben hacer lo mismo al recibir comentarios de la revisión por pares.

* Dar y recibir criticismos es muchas veces un proceso que conlleva inevitablemente reacciones emocionales - los autores y los revisores pueden subjetivamente acordar o no cómo presentar los resultados y/o que es lo que necesita mejora, enmienda o corrección. En el caso de identidades abiertas y/o reportes abiertos, la transparencia podría exacerbar dichas dificultades. Es entonces esencial que los revisores aseguren comunicar los puntos de una manera clara y civilizada, de manera de maximizar las oportunidades de que sea recibido como retroalimentación valiosa por el autor\(es\).

* La falta de anonimidad de los revisores en el caso de identidades abiertas puede subvertir el proceso al desincentivar que los revisores hagan críticas fuertes, especialmente en contra de colegas de estatus superior. 

* Finalmente, debido a estos temas, los revisores potenciales podrían ser más propensos a declinar la solicitud de revisión. 

#### Métricas abiertas

La [Declaración de San Francisco sobre Evaluación de la Investigación \(DORA\)](https://sfdora.org/) recomienda distanciarse de las evaluaciones basadas en revistas científicas, considerando todos los tipos de productos y utilizar varias formas de métricas y evaluaciones narrativas en paralelo. DORA ha sido firmada por miles de investigadores, instituciones, editoriales y agencias de financiamiento, quienes hoy se han comprometido a poner esto en práctica. El [Manifiesto de Leiden](http://www.leidenmanifesto.org/) provee guías sobre cómo utilizar las métricas de manera responsable.

Con respecto a Altmétricas, Priem et al. (2010) aconsejan que las altmétricas tienen los siguientes beneficios: se acumulan de manera más rápida que las citaciones; pueden medir el impacto de los resultados de la investigación distintos de publicaciones científicas (ej. sets de datos, código, protocolos, posteos de blog, tweets, etc.); y pueden proveer distintas medidas de impacto para proyectos individuales. La temporalidad de las almétricas se presenta como una ventaja para investigadores jóvenes, cuyo impacto de investigación puede no estar aún reflejado en un número significativo de citaciones, aún cuando su progresión en la carrera académica dependa de evaluaciones positivas. En adición, las altmétricas pueden ayudar con la identificación temprana de investigación influyente y conexiones potenciales entre investigadores. Un reporte reciente del grupo experto en Altmétricas de la Comisión Europea (Directiva General para Investigación e Innovación, Comisión Europa, 2017) ha identificado desafíos de altmétricas, incluyendo la falta de robustez y su susceptibilidad a ser trucado; que cualquier medida cesa de ser una buena medida una vez que se convierte en un objetivo (‘Ley de Goodhart’); la relativa falta de adopción de redes sociales en algunas disciplinas y regiones geográficas; y la dependencia de entidades comerciales sobre los datos en que se basan estas métricas. 

## <img src="/Images/Icons/gears.png" width="150" height="150" />
### Competencias

Ejercicios de ejemplo

* Los estudiantes trabajan en grupos de tres. Cada individuo escribe una revisión de un texto académico corto.

* Revisar una publicación de un servidor de pre-print. 

* Uso de servicios bibliométricos o de almétricas libres  \(ej. Impactstory, Paperbuzz, Altmetric bookmarklet, Dimensions.ai\) para buscar las métricas de un paper, y luego escribir una breve explicación de cómo exactamente distintas métricas reportadas por cada servicio son calculadas \(es más difícil se lo que piensas; incluye el desafío de encontrar la documentación apropiada de las métricas para incluso aquellos servicios que parecen ser los más transparentes\)

## <img src="/Images/Icons/questions.png" width="150" height="150" />
### Preguntas, obstáculos e ideas equivocadas comunes 
Q: ¿Es justa la evaluación de la investigación?

A: La evaluación de la investigación es justa así como sus métodos y técnicas de evaluación. Las métricas y almétricas tratan de medir la calidad de la investigación a través de la cantidad de productos, lo que puede ser acertado, pero no necesariamente. 


## <img src="/Images/Icons/output.png" width="150" height="150" />
### Resultados de aprendizaje

1. Los estudiantes serán capaces de identificar las revistas de revisión de pares abierta.
2. Los estudiantes estarán al tanto de un rango de métricas, sus ventajas y desventajas. 

## <img src="/Images/Icons/magnifying_glass.png" width="150" height="150" />
### Bibliografía sugerida

* Peer Review the Nuts and Bolts. [A Guide for Early Career Researchers.](http://senseaboutscience.org/wp-content/uploads/2016/09/peer-review-the-nuts-and-bolts.pdf)

* [Peer Reviewers’ Openness Initiative](https://opennessinitiative.org/)

* [Open Rev. ](https://www.openrev.org/)

* [Peerage of Science](https://www.peerageofscience.org/)

* [Make Data Count](https://makedatacount.org/)

* [OpenUP Hub](https://www.openuphub.eu/review)

* [Leiden Manifesto for Research Metrics](http://www.leidenmanifesto.org/)

* [Responsible Metrics](https://responsiblemetrics.org/)

* [NISO Alternative Assessment Metrics \(Altmetrics\) Initiative](http://www.niso.org/standards-committees/altmetrics)

* [Snowball Metrics](https://www.snowballmetrics.com/)

* Directorate-General for Research and Innovation (European Commission): Evaluation of Research Careers Fully Acknowledging Open Science Practices: Rewards, Incentives and/or Recognition for Researchers Practicing Open Science. Report, 14 November 2017: [doi.org/10.2777/75255](https://doi.org/10.2777/75255)



